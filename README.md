# Feature-Selection

## 1. Definition of Feature Selection
- Selecting a subset of the input features for training the model, and ignoring the irrelevant or redundant ones. 
- i.e., Simply dropping features if the features have large number of missing values.

## 2. Why need FS?
- To reduce training time, by reducing the number of features.
- To make ML model to be simple and explainable.
- To avoid poor quality model, by excluding non-informative features.

## 3. Method
1. Filter: Correlation, Chi-square
2. Wrapper: Recursive Feature Elimination
3. Embedded: Lasso

## Reference:
https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2?gi=b724c65b5151

